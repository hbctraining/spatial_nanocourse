[
  {
    "objectID": "lessons/visium_hd.html",
    "href": "lessons/visium_hd.html",
    "title": "Visium HD Analysis",
    "section": "",
    "text": "Approximate time: 2 hours and 45 minutes"
  },
  {
    "objectID": "lessons/visium_hd.html#mouse-brain-visium-hd",
    "href": "lessons/visium_hd.html#mouse-brain-visium-hd",
    "title": "Visium HD Analysis",
    "section": "Mouse Brain Visium HD",
    "text": "Mouse Brain Visium HD\nThe Visium HD platform is compatible with human and mouse fresh frozen, fixed frozen, and formalin-fixed parrafin-embedded (FFPE) tissue sections. For this lesson, we will be working with data from a fresh frozen coronal section of a mouse brain sample.\nEach Visium HD slide has the same 6.5 x 6.5mm capture area as previous Visium products but is covered with about 11 million tiles. These 2µm x 2µm squares are arrayed in a continuous lawn across the entire capture area. The squares are each uniquely barcoded with an oligonucleotide and contain probes allowing for the detection of the full coding transcriptome."
  },
  {
    "objectID": "lessons/visium_hd.html#preprocessing-data-with-spaceranger",
    "href": "lessons/visium_hd.html#preprocessing-data-with-spaceranger",
    "title": "Visium HD Analysis",
    "section": "Preprocessing Data with SpaceRanger",
    "text": "Preprocessing Data with SpaceRanger\nSequencing facilities often output scRNA-seq data, including spatial scRNA-seq data, in FASTQ format. Because this is Visium HD data from 10X Genomics, we used their proprietary pre-processing software Space Ranger to process the FASTQ files into a count matrix and other images. Specifically, the spaceranger count command aligns the reads in the FASTQ files against a transcriptomic reference and provides their spatial location using the oligonucleotide barcode.\nNote that Space Ranger requires a Linux system with at least 32 cores, 64GB of RAM, and 1TB of disk space.\n\n\n\n\n\n\nExample spaceranger count command\n\n\n\n\n\nA sample command for running spaceranger count is:\n\nspaceranger count --id=hd_count \\\n   --transcriptome=/path/to/refdata-gex-GRCh38-2020-A \\\n   --fastqs=/path/to/fastq \\\n   --probe-set=/path/to/Visium_Human_Transcriptome_Probe_Set_v2.0_GRCh38-2020-A.csv \\\n   --slide=H1-YD7CDZK \\\n   --area=A1 \\\n   --cytaimage=/path/to/CAVG10539_2023-11-16_14-56-24_APPS115_H1-YD7CDZK_A1_S11088.tif \\\n   --image=/path/to/APPS115_11088_rescan_01.btf \\\n   --create-bam=false\n\n\n\n\nWhen spaceranger count completes successfully, it will generate a variety of outputs (seen below), which will enable the analyst to perform further analysis in R/Python or using the proprietary Loupe browser from 10X Genomics. A good starting point is to take a look at the QC of the sample in the web summary, which we have provided in reports/ folder that you downloaded.\n\n\n\nIn the Visium HD assay, Space Ranger also bins the data in square of various sizes, including:\n\n2µm x 2µm bins\n8µm x 8µm bins\n16µm x 16µm bins\n\nHaving access to 2μm bins along with matching morphology information provides a great opportunity for reconstructing single cells from the data. However, because the 2µm x 2µm squares (and even the 8µm x 8µm bins) are so small, there is a potential for very little biological signal to be captured per bin. Additionally, the sheer number of bins at these higher resolutions can present challenges in terms of computational time and resources.\nFor this lesson, we will use the 16µm x 16µm bins of the cropped Visium HD slide to run locally on laptops."
  },
  {
    "objectID": "lessons/visium_hd.html#analysis-workflow",
    "href": "lessons/visium_hd.html#analysis-workflow",
    "title": "Visium HD Analysis",
    "section": "Analysis workflow",
    "text": "Analysis workflow\n\n\n\n\nSetting up\nFor this module, we will be working within an RStudio project. In order to follow along you should have downloaded the R project.\n\n\n\n\n\n\nImportant\n\n\n\nIf you haven’t done this already, the project is located in “Dataset for workshop” -&gt; “Day 2- NGS-based- VisiumHD” in the course DropBox.\n\n\nOnce downloaded, you should see a file called visiumHD_nanocourse.zip on your computer (likely, in your Downloads folder).\n\nUnzip this file. This will result in a folder of the same name.\nMove the folder to the location on your computer where you would like to perform the analysis.\nOpen up the folder. The contents will look like the screenshot below:\n\n\n\nLocate the .Rproj file and double-click on it. This will open up RStudio with the “visiumHD_nanocourse” project loaded.\nOpen a new Rscript file.\nStart with some comments to indicate what this file is going to contain:\n\n\n# February 26th, 2025\n# Spatial Transcriptomics: Session 2\n\n\nSave the Rscript in the code folder as visiumHD.R. Your working directory should look something like this:"
  },
  {
    "objectID": "lessons/visium_hd.html#loading-libraries",
    "href": "lessons/visium_hd.html#loading-libraries",
    "title": "Visium HD Analysis",
    "section": "Loading Libraries",
    "text": "Loading Libraries\nNext, we will need to be sure to load the libraries that we will be using:\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(Seurat)\nlibrary(qs)\nlibrary(SeuratWrappers)\nlibrary(Banksy)\nlibrary(quadprog)\nlibrary(spacexr)\n\n# Increases the size of the default vector\noptions(future.globals.maxSize= 2000000000)"
  },
  {
    "objectID": "lessons/visium_hd.html#creating-the-seurat-object",
    "href": "lessons/visium_hd.html#creating-the-seurat-object",
    "title": "Visium HD Analysis",
    "section": "Creating the Seurat Object",
    "text": "Creating the Seurat Object\nThe Seurat object is a custom list-like object that has well-defined spaces to store specific information/data for single-cell experiments, including spatial experiments and Visium HD.\nThe Seurat package provides a function Load10X_Spatial() to easily create a Seurat object from the output of Space Ranger. The Load10X_Spatial function takes as input the feature matrix and the low-resolution tissue image from the output of Space Ranger and generates a Seurat object containing both gene-level counts and spatial information.\nWe will not have you run this code, as this can take some time and the Space Ranger output files are quite large to share. Instead, you will load the pre-made Seurat object.\n\n\n\n\n\n\nClick here to see the R code used to create the Seurat object\n\n\n\n\n\n\nlocaldir &lt;- '../path/to/spaceranger/outs/'\n\n#Load the raw feature matrix\nobject &lt;- Load10X_Spatial(data.dir = localdir,\n                          filename = 'raw_feature_bc_matrix.h5',\n                          bin.size = 16)\n\n\n\n\n\nExplore the object\nLet’s read in the Seurat object and talk about some very basic slots that we will be accessing.\n\n# Load in Seurat object\nobject &lt;- qread('data_processed/MsBrain_FF-A1_subset_misc.qs')\n\nWe can print the Seurat object by using:\n\nobject\n\nAn object of class Seurat \n32285 features across 43167 samples within 1 assay \nActive assay: Spatial.016um (32285 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: slice1.016um\n\n\nNow we can examine its major features, which we will add to and alter throughout the lesson:\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThere are 3 things about our Seurat object printout that would be different if we were using the 8µm x 8µm binning instead of the 16µm x 16µm binning. What are these three differences?\n\n\n\n\n\n\nClick here to use an app that lets you explore different bin sizes for this Seurat object"
  },
  {
    "objectID": "lessons/visium_hd.html#quality-control",
    "href": "lessons/visium_hd.html#quality-control",
    "title": "Visium HD Analysis",
    "section": "Quality Control",
    "text": "Quality Control\nThe main objective of quality control is to filter the data so that we include only data from bins that are of high-quality. This makes it so that when we cluster our bins, it is easier to identify distinct cell type populations.\n\n\n\nIn Visium HD data, the main challenge is in delineating bins that are poor quality from bins containing reads from less complex cells. If you expect a particular cell type in your dataset to be less transcriptionally active as compared other cell types in your dataset, the bins underneath this cell type will naturally have fewer detected genes and transcripts. However, having fewer detected genes and transcripts can also be a technical artifact and not a result of biological signal.\nVarious metrics can be used to filter low-quality bins from high-quality ones, including:\n\nUMI counts per bin - This is the number of unique transcripts detected per bin. Because the bins are very small, this number is less than what we would expect for non-spatial scRNA-seq data.\nGenes detected per bin - This is the number of unique genes detected per bin. Again, because the bins are very small, this number is less than what we would expect for non-spatial scRNA-seq data.\nComplexity (novelty score) - The novelty score is computed as shown below:\n\n\n\nIf there are many captured transcripts (high nUMI) and a low number of genes detected in a bin, this likely means that you only captured a low number of genes and simply sequenced transcripts from those lower number of genes over and over again. These low complexity (low novelty) bins could represent a specific cell type (i.e. red blood cells, which lack a typical transcriptome), or could be due to an artifact or contamination. Generally, we expect the complexity score to be above 0.80 for good-quality bins.\nMitochondrial counts ratio - This metric can identify whether there is a large amount of mitochondrial contamination from dead or dying cells. We define poor-quality samples for mitochondrial counts as bins which surpass the 0.2 mitochondrial ratio threshold, unless of course you are expecting this in your sample. This ratio is computed as:\n\n\n\n\nLet’s take a quick look at the data and make a decision on whether we need to apply any filtering. We will examine the distributions of UMI counts per bin and genes detected per bin to determine reasonable thresholds for those metrics to implement during QC filtering.\n\nPre-filtering\nTo create some plots first, we will need to create a metadata object using this command:\n\nobject_meta &lt;- object@meta.data\n\nNow we can plot the number of UMIs (nUMI) and the number of genes (nGene) side-by-side. For both of the plots, we expect to see a bimodal distribution, with one peak representing bins containing lower-quality cells with fewer genes and UMIs and another peak representing bins containing healthy cells with more genes and UMIs. Ideally, the peak representing lower-quality and dying cells is small and the peak representing healthy cells is large.\n\n# Create a plot for nUMI\ndist_counts_before &lt;- object_meta %&gt;%\n  ggplot(aes(x=nCount_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of UMIs per bin\") +\n  ggtitle('Pre-QC UMIs/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Create a plot for nGene\ndist_features_before &lt;- object_meta %&gt;%\n  ggplot(aes(x=nFeature_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of genes per bin\") +\n  ggtitle('Pre-QC Genes/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\ndists_before &lt;- dist_counts_before | dist_features_before\ndists_before\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUsing the distribution plots in the app below, what do you think would be good minimum thresholds for nGene and nUMI?\n\n\n\n\n\n\n\n\nPost-Filtering\nWe will apply very minimal filtering here, with nUMI &gt; 100 and nGene &gt; 100. It has been shown that low expression can be biologically meaningful for spatial context so we won’t be as stringent as we normally are with scRNA-seq.\n\n# Create a filtered object\nobject_filt &lt;- subset(object, \n                      subset = (nCount_Spatial.016um &gt; 100) & \n                        (nFeature_Spatial.016um &gt; 100))\n\nNow, we can create similar plots with filtered data. As expected, we see that the small left peak in the distribution has vanished, leaving the higher quality bins, which are the majority of the data.\n\n# Create a new metadata data frame \nobject_filt_meta &lt;- object_filt@meta.data\n\n# Plot nUMI\ndist_counts_after &lt;- object_filt_meta %&gt;%\n  ggplot(aes(x=nCount_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of UMIs per bin\") +\n  ggtitle('PostQC UMIs/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot nGene\ndist_features_after &lt;- object_filt_meta %&gt;%\n  ggplot(aes(x=nFeature_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of genes per bin\") +\n  ggtitle('PostQC Genes/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Combine plots side-by-side\ndists_after &lt;- dist_counts_after | dist_features_after\ndists_after\n\n\n\n\n\n\n\n\n\n\nVisualizing Counts Data\nWe can visualize the number of UMIs and gene counts per bin, both as a distribution and layered on top of the tissue image. Let’s start with a violin plot to look at the distribution of UMI counts and gene counts. The input is our post-filtered dataset.\n\n# Violin plot of UMI counts\nvln_counts_after &lt;- VlnPlot(object_filt, \n                            features = \"nCount_Spatial.016um\", \n                            pt.size = 0, \n                            group.by = 'orig.ident') + \n  NoLegend() + scale_y_log10() + ggtitle('nUMI') + xlab('') + ylim(c(100, 15000))\n\n# Violin plot of gene counts\nvln_features_after &lt;- VlnPlot(object_filt, \n                            features = \"nFeature_Spatial.016um\", \n                            pt.size = 0, \n                            group.by = 'orig.ident') + \n  NoLegend() + scale_y_log10() + ggtitle('nGene') +  xlab('') + ylim(c(100, 15000))\n\n\n# Plot both side by side\nvln_counts_after | vln_features_after\n\n\n\n\n\n\n\n\nWe see that both distributions have a similar peak but the nUMI distribution has a much longer tail. This is expected, because while the small physical size of the bins means that most genes will be detected only once or twice, a minority of bins under very transcriptionally active cells may exhibit multiple transcripts of the same gene.\nNext, we can look at the same metrics and the distribution on the actual image itself. Note that many spots have very few counts, in part due to low cellular density or cell types with low complexity in certain tissue regions.\n\n# Visualizing UMI count across the image\nimage_counts &lt;- SpatialFeaturePlot(object_filt, \n                                   feature = 'nCount_Spatial.016um', \n                                   pt.size.factor = 8)\n\n# Visualizing gene count across the image\nimage_features &lt;- SpatialFeaturePlot(object_filt, \n                                     features = \"nFeature_Spatial.016um\", \n                                     pt.size.factor = 8) \n\n# Plot the two side-by-side\nimage_counts | image_features"
  },
  {
    "objectID": "lessons/visium_hd.html#normalize-data",
    "href": "lessons/visium_hd.html#normalize-data",
    "title": "Visium HD Analysis",
    "section": "Normalize Data",
    "text": "Normalize Data\nNormalization is important in order to make expression counts comparable across genes and/or samples. We note that the best normalization methods for spatial data are still being developed and evaluated. In particular, Bhuva et. al tested a variety of normalization techniques and found that normalizing by the number of transcripts detected per bin negatively affects spatial domain identification because total detections per bin can represent real biology. We are cognizant of this, but as discussed earlier, it can be challenging to determine whether a bin has few detections because of a technical artifact or biological signal. In the absence of normalization, this lack of signal will strongly affect clustering regardless of whether it is technical or biological. For this reason, we apply a standard log-transformed library size normalization to our data.\n\nobject_filt &lt;- NormalizeData(object_filt, assay = 'Spatial.016um')\n\nAfter normalization, we can call our Seurat object with:\n\nobject_filt\n\nAn object of class Seurat \n32285 features across 41818 samples within 1 assay \nActive assay: Spatial.016um (32285 features, 0 variable features)\n 2 layers present: counts, data\n 1 spatial field of view present: slice1.016um\n\n\nAnd we can see that there is now a new “data” layer in the Seurat object."
  },
  {
    "objectID": "lessons/visium_hd.html#unsupervised-clustering",
    "href": "lessons/visium_hd.html#unsupervised-clustering",
    "title": "Visium HD Analysis",
    "section": "Unsupervised Clustering",
    "text": "Unsupervised Clustering\nThe authors of the Seurat package recommend the Seurat v5 sketch clustering workflow because it exhibits improved performance for large datasets, especially for identifying rare and spatially-restricted groups. Sketch-based analyses aim to “subsample” large datasets in a way that preserves rare populations.\n\n\n\nWe will start by defining a set of highly variable genes. Note that this is being done on all bins in our object. Using this list of genes will help us to quantify the variability and similarity between bins.\n\nobject_filt &lt;- FindVariableFeatures(object_filt)\n\nWe can examine our Seurat object and see that FindVariableFeatures() has added 2,000 variable features.\n\nobject_filt\n\nAn object of class Seurat \n32285 features across 41818 samples within 1 assay \nActive assay: Spatial.016um (32285 features, 2000 variable features)\n 2 layers present: counts, data\n 1 spatial field of view present: slice1.016um\n\n\n\n\n\nNext, we select 10,000 cells and create a new sub-sampled “sketch” assay using the SketchData() function. The function takes a normalized single-cell dataset containing a set of variable features and returns a Seurat object with a new assay (sketch), consisting of 10,000 bins selected based off a “leverage score” for each bin. The leverage score reflects the magnitude of its contribution to the gene-covariance matrix, and its importance to the overall dataset, with rare populations earning a higher leverage score. This means that our 10,000 cells selected for the sketch will oversample rare populations, retaining the biological complexity of the sample, while drastically compressing the dataset.\n\n# we select 10,000 cells and create a new 'sketch' assay\nobject_filt &lt;- SketchData(\n  object = object_filt,\n  assay = 'Spatial.016um',\n  ncells = 10000,\n  method = \"LeverageScore\",\n  sketched.assay = \"sketch\"\n)\n\nNow that we have the sketched data, we can call the Seurat object:\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 2 layers present: counts, data\n 1 other assay present: Spatial.016um\n 1 spatial field of view present: slice1.016um\n\n\nWe will see that there are four major changes that have taken place:\n\nThe number of features in the second line has double, because we have added a new assay\nAccordingly, the number of assays has increased from one to two\nThe active assay has change from Spatial.016um to sketch\nThere is a new line listing additional assays that exist in the Seurat object\n\n\n\n\nWe can also see that the leverage score has been added as a column to the metadata of our object.\n\nView(object_filt@meta.data)\n\n\n\n\n\n\n\nNext, we will peform a standard clustering workflow on our sketch of 10,000 cells:\n\nFindVariableFeatures: As before, this generates a list of highly variable genes, which may be slighly different for the sketched dataset than for the full dataset\nScaleData: Highly variable genes will be confounded with the most highly expressed genes, so we need to adjust for this\nRunPCA: Perform a principal component analysis using our scaled data and variable genes. This will emphasize variation in gene expression as well as similarity across bins\nFindNeighbors: Determine the Euclidean distance between bins in PCA space\nFindClusters: Iteratively group bins together based on neighborhood distances. Higher resolution will yield more groups.\n\n\nobject_filt &lt;- FindVariableFeatures(object_filt)\nobject_filt &lt;- ScaleData(object_filt)\nobject_filt &lt;- RunPCA(object_filt, assay = \"sketch\", \n                      reduction.name = \"pca.sketch\")\nobject_filt &lt;- FindNeighbors(object_filt, assay = \"sketch\", \n                             reduction = \"pca.sketch\", dims = 1:50)\nobject_filt &lt;- FindClusters(object_filt, \n                            cluster.name = \"seurat_cluster.sketched\", \n                            resolution = .65)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10000\nNumber of edges: 401729\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9013\nNumber of communities: 20\nElapsed time: 0 seconds\n\n\nFinally, let’s create a UMAP using the principal components as input. UMAP is a method that aims to place cells with similar local neighborhoods in high-dimensional space together in low-dimensional space, which is useful for visualizing our newly calculated clusters. We observe good separation between groups annotated as separate clusters, which is sign that our clustering indeed represents various cell types.\n\nobject_filt &lt;- RunUMAP(object_filt, reduction = \"pca.sketch\", \n                       reduction.name = \"umap.sketch\", return.model = T, \n                       dims = 1:50)\n\n# Plot UMAP\nDimPlot(object_filt, reduction = \"umap.sketch\", label = T, \n        cols = 'polychrome') + \n  ggtitle(\"Sketched clustering\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe can also examine our object after these manipulations and note the addition of the scale.data layer as well as the sketch PCA and UMAP dimensional reductions.\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.016um\n 2 dimensional reductions calculated: pca.sketch, umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nShould return:"
  },
  {
    "objectID": "lessons/visium_hd.html#project-cluster-labels-back-to-the-full-dataset",
    "href": "lessons/visium_hd.html#project-cluster-labels-back-to-the-full-dataset",
    "title": "Visium HD Analysis",
    "section": "Project cluster labels back to the full dataset",
    "text": "Project cluster labels back to the full dataset\nNow that we have our clusters and dimensional reductions from our sketched dataset, we need to extend these to the full dataset. The ProjectData function projects all the bins in the dataset (the Spatial.016um assay) onto the sketch assay.\n\nobject_filt &lt;- ProjectData(\n  object = object_filt,\n  assay = \"Spatial.016um\",\n  full.reduction = \"full.pca.sketch\",\n  sketched.assay = \"sketch\",\n  sketched.reduction = \"pca.sketch\",\n  umap.model = \"umap.sketch\",\n  dims = 1:50,\n  refdata = list(seurat_cluster.projected = \"seurat_cluster.sketched\")\n)\n\nUsing the sketch PCA and UMAP, the ProjectData function returns a Seurat object that includes: * Dimensional reduction (PCA) - The full.pca.sketch dimensional reduction extends the PCA reduction on the sketched cells to all bins in the dataset * Dimensional reduction (UMAP) - The full.umap.sketch dimensional reduction extends the UMAP reduction on the sketched cells to all bins in the dataset * Cluster labels - The seurat_cluster.projected column in the object metadata now labels all cells in the dataset with one of the cluster labels derived from the sketched cells\nWe can now see the additional full-dataset reductions in the object.\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.016um\n 4 dimensional reductions calculated: pca.sketch, umap.sketch, full.pca.sketch, full.umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nShould return:\n\n\n\nNote that a score for the projection of each bin will be saved as a column in the metadata. Actually opening up the metadata again gives the opportunity to look at the seurat_cluster.sketched column and see many NA values, because it was only calculated for 10,000 bins. The seurat_cluster.projected shows values for every bin.\n\nView(object_filt@meta.data)\n\n\n\n\n\n\n\nShould return:\n\nVisualizing the projected clusters on UMAP\nWe can now visualize our clusters from the projected assignments. The UMAP plot now contains more points, which is expected because we are now visualizing the full dataset rather than our 10,000 bin sketch. Nonetheless, we can see that the full dataset is still well-representated by the projected dimensional reduction and clustering.\n\n# switch to full dataset assay\nDefaultAssay(object_filt) &lt;- \"Spatial.016um\"\n\n# Change the idents to the projected cluster assignments\nIdents(object_filt) &lt;- \"seurat_cluster.projected\"\n\n# Plot the UMAP\nDimPlot(object_filt, reduction = \"full.umap.sketch\", label = T, raster = F, \n              cols = 'polychrome') +\n  ggtitle(\"Projected clustering\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nVisualizing projected clusters on the image\nIn order to see the clusters superimposed on our image we can use the SpatialDimPlot() function. We will also set the color palette and convert the cluster assignments to a factor so they are ordered numerically rather than lexicographically in the figure.\n\n# Arrange so clusters get listed in numerical order\nobject_filt$seurat_cluster.projected &lt;- object_filt$seurat_cluster.projected %&gt;% \n  as.numeric %&gt;% as.factor()\n\n# Set color palette\ncolor_pal &lt;- Seurat::DiscretePalette(n = length(unique(object_filt$seurat_cluster.projected)),\n                                    palette = \"polychrome\")\nnames(color_pal) &lt;- sort(unique(object_filt$seurat_cluster.projected))\nimage_seurat_clusters &lt;- SpatialDimPlot(object_filt, \n                                        group.by = 'seurat_cluster.projected', \n                                        pt.size.factor = 8, cols = color_pal) +\n  guides(fill=guide_legend(ncol=2))\n\nimage_seurat_clusters"
  },
  {
    "objectID": "lessons/visium_hd.html#spatially-informed-clustering",
    "href": "lessons/visium_hd.html#spatially-informed-clustering",
    "title": "Visium HD Analysis",
    "section": "Spatially-informed Clustering",
    "text": "Spatially-informed Clustering\nBANKSY is another method for performing clustering. Unlike Seurat, BANKSY takes into account not only an individual bin’s expression pattern but also the mean and the gradient of gene expression levels in a bin’s broader neighborhood. This makes it valuable for identifying and defining spatial regions of interest.\nWe use the RunBanksy function to create a new “BANKSY” assay based on a default of the 4,000 most highly variable features, which can be used for dimensionality reduction and clustering. Two parameters of importance are: * k_geom - Number of bins to consider for the local neighborhood. Larger values will yield larger domains. * lambda - Influence of the neighborhood. Larger values yield more spatially coherent domains. The authors recommend using 0.8 to identify broader spatial domains.\n\n# Run Banksy\nobject_filt &lt;- RunBanksy(object_filt, lambda = 0.8, verbose = T,\n                         assay = 'Spatial.016um', slot = 'data', k_geom = 50)\n\nWe can see the new BANKSY assay in our object by calling:\n\nobject_filt\n\nAn object of class Seurat \n68570 features across 41818 samples within 3 assays \nActive assay: BANKSY (4000 features, 0 variable features)\n 2 layers present: data, scale.data\n 2 other assays present: Spatial.016um, sketch\n 4 dimensional reductions calculated: pca.sketch, umap.sketch, full.pca.sketch, full.umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nWhich should return:\n\n\n\nWe perform a simplified clustering workflow on the BANKSY assay.\n\nobject_filt &lt;- RunPCA(object_filt, assay = \"BANKSY\", \n                      reduction.name = \"pca.banksy\", \n                      features = rownames(object_filt), npcs = 30)\nobject_filt &lt;- FindNeighbors(object_filt, reduction = \"pca.banksy\", \n                             dims = 1:30)\nobject_filt &lt;- FindClusters(object_filt, cluster.name = \"banksy_cluster\",\n                            resolution = 0.5)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 41818\nNumber of edges: 1067042\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9496\nNumber of communities: 24\nElapsed time: 2 seconds\n\n\nLet’s visualize the BANKSY clusters alongside the Seurat clusters for a side-by-side comparison:\n\ncolor_pal &lt;- Seurat::DiscretePalette(n = length(unique(object_filt$banksy_cluster)),\n                                    palette = \"polychrome\")\nnames(color_pal) &lt;- sort(unique(object_filt$banksy_cluster))\n\nimage_banksy_clusters &lt;- SpatialDimPlot(object_filt, group.by = \"banksy_cluster\",\n                                        pt.size.factor = 7, cols = color_pal)\n\nimage_seurat_clusters | image_banksy_clusters\n\n\n\n\n\n\n\n\nWe can see that, as expected, the BANKSY clusters are more spatially-restricted, or more compact, than the Seurat clusters. We also see that the BANKSY clusters are less noisy than the Seurat clusters, likely because of the smoothing effect of considering a cell’s spatial neighborhood when assigning a cluster label.\n\n\n\n\n\n\nClick here to see BANKSY using a lambda value of 0.2\n\n\n\n\n\nIf we had run BANKSY with lambda = 0.2, as recommended for cell type clustering instead of lambda = 0.8 for spatial domain clustering, the resultant clusters would be less spatially restricted (in other words less compact and more distributed throughout the image) and more similar to our Seurat clustering. Below is a figure using lamba=0.2 in BANKSY rather than lamba=0.8."
  },
  {
    "objectID": "lessons/visium_hd.html#cell-type-annotation",
    "href": "lessons/visium_hd.html#cell-type-annotation",
    "title": "Visium HD Analysis",
    "section": "Cell Type Annotation",
    "text": "Cell Type Annotation\nPerhaps we are particularly interested in understanding the organization of cell types in the cortical region of the brain.\n\n\n\nWe first subset our Seurat object to this region of interest. There are multiple ways of subsetting a Seurat object to a region of interest, but here we have identified a handful of cluster numbers that appear almost exclusively in the cortical region, and we will subset the object to only include cells that are assigned these cluster numbers.\n\ncortex &lt;- subset(object_filt, seurat_cluster.projected %in% c(18, 19, 7, 2, 4))\n\ncolor_pal &lt;- Seurat::DiscretePalette(n = length(unique(object_filt$seurat_cluster.projected)),\n                                    palette = \"polychrome\")\nnames(color_pal) &lt;- sort(unique(object_filt$seurat_cluster.projected))\nSpatialDimPlot(cortex, group.by = 'seurat_cluster.projected', \n               pt.size.factor = 8, cols = color_pal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: Your colors may be different than the ones in the above figure.\n\n\nTo perform accurate annotation of cell types, we must also take into consideration that our 16µm x 16µm bins may contain one or more cells each. The method Robust Cell Type Deconvolution (RCTD) has been shown to accurately annotate spatial data from a variety of technologies while taking into consideration that a single bin may exhibit multiple cell type profiles.\nRCTD takes a cell-type-annotated scRNA-seq dataset as a reference and a spatial dataset as a query. For our reference, we will use a subsampled version of the mouse scRNA-seq dataset from the Allen Brain Atlas. We will use our cortex Seurat object as the spatial query. As an overview, the process is as follows:\n\nSketch and process the spatial query dataset\nLoad and format the scRNA-seq reference dataset\nApply RCTD to deconvolute the “sketched” cortical cells and annotate them\nProject these annotations onto the full cortical dataset.\n\n\n1) Sketch and process the spatial query dataset\n\nDefaultAssay(cortex) &lt;- 'Spatial.016um'\ncortex &lt;- FindVariableFeatures(cortex)\ncortex &lt;- SketchData(\n  object = cortex,\n  ncells = 3000,\n  method = \"LeverageScore\",\n  sketched.assay = \"sketch\"\n)\n\nDefaultAssay(cortex) &lt;- \"sketch\"\ncortex &lt;- ScaleData(cortex)\ncortex &lt;- RunPCA(cortex, assay = \"sketch\", \n                 reduction.name = \"pca.cortex.sketch\", verbose = T)\ncortex &lt;- FindNeighbors(cortex, reduction = \"pca.cortex.sketch\", dims = 1:50)\ncortex &lt;- RunUMAP(cortex, reduction = \"pca.cortex.sketch\", \n                  reduction.name = \"umap.cortex.sketch\", return.model = T, \n                  dims = 1:50, verbose = T)\n\n# create the RCTD query object\ncounts_hd &lt;- cortex[[\"sketch\"]]$counts\ncortex_cells_hd &lt;- colnames(cortex[[\"sketch\"]])\ncoords &lt;- GetTissueCoordinates(cortex)[cortex_cells_hd, 1:2]\nquery &lt;- SpatialRNA(coords, counts_hd, colSums(counts_hd))\n\n\n\n2) Load and format the reference dataset\n\nmem.maxVSize(15000)\n\n[1] 15000\n\nref_subset &lt;- qread(\"data_processed/allen_scRNAseq_ref_subset.qs\")\n\nIdents(ref_subset) &lt;- \"subclass_label\"\ncounts &lt;- ref_subset[[\"RNA\"]]$counts\ncluster &lt;- as.factor(ref_subset$subclass_label)\nnUMI &lt;- ref_subset$nCount_RNA\nlevels(cluster) &lt;- gsub(\"/\", \"-\", levels(cluster))\ncluster &lt;- droplevels(cluster)\n\n# create the RCTD reference object\nreference &lt;- Reference(counts, cluster, nUMI)\n\n\n\n3) Apply RCTD to deconvolute the “sketched” cortical cells and annotate them\nNote that run.RCTD takes 10-15 minutes to complete on a laptop using 6 cores\n\n# run RCTD\nRCTD &lt;- create.RCTD(query, reference, max_cores = 6)\n\n\n          Astro        CA1-ProS       CA2-IG-FC             CA3            Car3 \n            500             500             101             442             500 \n             CR          CT SUB              DG            Endo      L2 IT ENTl \n            208             500             500             500             500 \n     L2 IT ENTm     L2-3 IT CTX    L2-3 IT ENTl     L2-3 IT PPP     L2-3 IT RHP \n            433             500             500             500             500 \n      L3 IT ENT      L4 RSP-ACA     L4-5 IT CTX       L5 IT CTX          L5 PPP \n            500             500             500             500             254 \n      L5 PT CTX L5-6 IT TPE-ENT     L5-6 NP CTX       L6 CT CTX       L6 IT CTX \n            500             500             500             500             500 \n     L6 IT ENTl         L6b CTX      L6b-CT ENT           Lamp5       Micro-PVM \n            273             500             500             500             500 \n         NP PPP          NP SUB           Oligo           Pvalb        SMC-Peri \n            500             398             500             500             285 \n           Sncg             Sst       Sst Chodl        SUB-ProS             Vip \n            500             500             495             500             500 \n           VLMC \n            152 \n\nRCTD &lt;- run.RCTD(RCTD, doublet_mode = \"doublet\") # this command takes ~15 mins to run\n\n[1] \"gather_results: finished 1000\"\n[1] \"gather_results: finished 2000\"\n[1] \"gather_results: finished 3000\"\n\n# add results back to Seurat object\ncortex &lt;- AddMetaData(cortex, metadata = RCTD@results$results_df)\n\n\n\n4) Project RCTD labels onto all cortical cells\n\ncortex$first_type &lt;- as.character(cortex$first_type)\ncortex$first_type[is.na(cortex$first_type)] &lt;- \"Unknown\"\ncortex &lt;- ProjectData(\n  object = cortex,\n  assay = \"Spatial.016um\",\n  full.reduction = \"pca.cortex\",\n  sketched.assay = \"sketch\",\n  sketched.reduction = \"pca.cortex.sketch\",\n  umap.model = \"umap.cortex.sketch\",\n  dims = 1:50,\n  refdata = list(full_first_type = \"first_type\")\n)\n\nWe can see that the excitatory neurons are located in layers at varying cortical depths, as expected.\n\nIdents(cortex) &lt;- \"full_first_type\"\ncells &lt;- CellsByIdentities(cortex)\n# Layered (starts with L), excitatory neurons in the cortex\nexcitatory_names &lt;- sort(grep(\"^L.* CTX\", names(cells), value = TRUE))\nSpatialDimPlot(cortex, cells.highlight = cells[excitatory_names], \n               cols.highlight = c(\"#FFFF00\", \"grey50\"), facet.highlight = T, \n               combine = T, ncol = 4, pt.size.factor = 8)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nSpatial Transcriptomics Nanocourse\n\n\n\nAudience\nComputational skills required\nDuration\n\n\n\n\nBiologists\nIntroduction to R\n1 session in-person (~1h 45 min of trainer-led time)\n\n\n\n\nDescription\nThis repository contains materials for a module which is part of a Nanocourse organized by the Single Cell Core at HMS. The nanocourse titled “Spatial Transcriptomics: Key Technologies, Experimental Considerations, and Data Analysis” introduces the fundamentals of data analysis for spatial transcriptomics, including common techniques and tools. In this module we walk through the analysis workflow for Visium HD data analysis.\n\n\nLearning Objectives\n\nDescribe the steps in a Visium HD analysis workflow\nUse Seurat and associated tools to perform analysis of spatial transcriptomics data, including QC metric evaluation, normalization, clustering, and marker identification\n\n\n\nDataset\nThe dataset which is used in the pre-reading activities can be found at the link below.\nVisium HD Dataset\n\n\nLessons\n\n\nVisium HD Analysis with Seurat\n\n\n\nInstallation Requirements\n\nApplications\nDownload the most recent versions of R and RStudio for your laptop:\n\nR (version 4.4.0 or above)\nRStudio\n\n\n\nPackages for R\n\n\n\n\n\n\nNotes for installing packages\n\n\n\nNote 1: Install the packages in the order listed below.\nNote 2:  All the package names listed below are case sensitive!\nNote 3: If you have a Mac with an M1 chip, download and install gfortran before installing your packages\nNote 4: At any point (especially if you’ve used R/Bioconductor in the past), in the console R may ask you if you want to update any old packages by asking Update all/some/none? [a/s/n]:. If you see this, type “a” at the prompt and hit Enter to update any old packages. Updating packages can sometimes take quite a bit of time to run, so please account for that before you start with these installations.\nNote 5: If you see a message in your console along the lines of “binary version available but the source version is later”, followed by a question, “Do you want to install from sources the package which needs compilation? y/n”, type n for no, and hit enter.\n\n\n(1) Install the packages listed below from CRAN using the install.packages() function.\n\nSFEData\nscuttle\nscater\nscran\nbluster\nBiocParallel\nVoyager\nfastverse\nggplot2\npals\ntidyverse\nSeurat\npatchwork\nqs\nquadprog\nremotes\ndevtools\nBiocManager\n\nPlease install them one-by-one as follows:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"Seurat\")\ninstall.packages(\"patchwork\")\n# & so on ...\n\n(2) Install the packages listed below from Bioconductor using the BiocManager::install() function.\n\nglmGamPoi\n\nPlease install glmGamPoi as follows:\n\nlibrary(BiocManager)\nBiocManager::install(\"glmGamPoi\")\nBiocManager::install(\"pachterlab/SpatialFeatureExperiment\", ref = \"devel\")\n\n(3) Install the packages listed below from GitHub using the given remotes:install_github or devtools::install_github command.\n\n# SeuratWrappers\nremotes::install_github('satijalab/seurat-wrappers')\n\n# Banksy\nremotes::install_github(\"prabhakarlab/Banksy@devel\")\n\n# spacexr\ndevtools::install_github(\"dmcable/spacexr\", build_vignettes = FALSE)\n\n(4) Finally, please check that all the packages were installed successfully by loading them one at a time using the library() function.\n\nlibrary(SpatialFeatureExperiment)\nlibrary(SFEData)\nlibrary(scuttle)\nlibrary(scater)\nlibrary(scran)\nlibrary(bluster)\nlibrary(BiocParallel)\nlibrary(Voyager)\nlibrary(fastverse)\nlibrary(ggplot2)\nlibrary(pals)\nlibrary(tidyverse)\nlibrary(Seurat)\nlibrary(patchwork)\nlibrary(qs)\nlibrary(quadprog)\nlibrary(remotes)\nlibrary(devtools)\nlibrary(BiocManager)\nlibrary(glmGamPoi)\nlibrary(SeuratWrappers)\nlibrary(Banksy)\nlibrary(spacexr)\n\n(5) Once all packages have been loaded, run sessionInfo().\n\nsessionInfo()"
  },
  {
    "objectID": "lessons/loupe_demo.html",
    "href": "lessons/loupe_demo.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "lessons/loupe_demo.html#loupe-browser",
    "href": "lessons/loupe_demo.html#loupe-browser",
    "title": "",
    "section": "Loupe Browser",
    "text": "Loupe Browser\nLoupe Browser is a visualization software from 10X genomics that allows you to explore and analyze your 10x Genomics Chromium and Visium data. You can also convert your Seurat objects into Loupe Browser files using the LoupeR package.\n\nLoad in the data\nWe will use the cloupe file created by spaceranger, as you will notice this the full image and not the cropped image we have been using so far in class. By default, Space Ranger count produces a cloupe file for Visium HD Spatial Gene Expression data using 8 µm x 8 µm bins (can change this using the --custom-bin-size option).\n\n\nView panel\nThe workspace is centered around the View Panel, showing an H&E brightfield image of the tissue section overlaid with spots representing Visium Spatial Gene Expression data. Zoom in so the image fills the View space. * Note the scale bar in the bottom right; set to 2mm by default * Spot opacity is controlled with slider, making individual spots more or less visible. * Projection settings allow the user to change individual settings, and then reset it back to original settings * Different projection types (UMAP, Feature plot), but we will stick to Spatial\n\n\nTool selector\nOn the left hand side you have the Tool selector:\nClusters\n\nDefault is set to Clusters - these are clusters determined by spaceranger (similar to what we observed in the spaceranger report)\n\nThe graph-based clustering algorithm consists of building a sparse nearest-neighbor graph, followed by Louvain Modularity Optimization - most similar to what is performed in Seurat\nk-means clustering, standard k-means where you need to specify the number k clusters you want\nUse the “Create new group” to upload a csv of your own cluster labels. First column, cellular barcodes and second column is cell annotation. The first column’s contents must match at least a subset of the barcodes in the .cloupe file\n\n\n\nHover over image, see the different clusters\nDe-select all and pick and choose select clusters (e.g. Cluster 14, 16 and 17) which outline the hippocampal region\nSee the Differential expression output table below and genes that have the highest FC in each cluster. Can export that data and filter to find consensus genes if we thought they were all one celltype. (cannot rename to categorize in Loupe; need unique names)\n\nFeatures\n\nUse the search box to look for the Prox1 gene; from the Allen Brain Atlas is observed to increased expression in Hippocampus. Defaults to log2 scale. Can change to linear scale. Turn on “Filter barcodes” and set the minimum to 1. This will omit bins with zero counts and help see where the gene is expressed exclusively on the tissue slide\nTry the same with Crlf1\nTry the same with Pkp2. See that different parts of the hippocampus are illuminated with each gene.\nSave this list of genes by “Edit list name” - HIP\n\nClick combine all below and look at expression on the image. Filter barcodes for 0.25.\nSave barcodes allows you to create a new cluster as part of a new group (HIP name of selected cluster; create a new group called “Celltype by marker expression).\nGo back to the Clusters tool\n\nTake a look at expression distribution below - violin plots highlight which clusters we are selecting cells from\n\nAdvanced selection\n\nAllows you to create rules. Do this using the same three hippocampal genes.\nSee how mnay barcodes you are left with when you use AND versus OR\n\nReanalyze\n\nA new box will pop up to guide you.\nThreshold by features, UMIs and then choose whether you want a new spatial plot and/or UMAP, can even tweak some parameters (“advanced”)"
  },
  {
    "objectID": "lessons/visium_hd.html#downloading-the-data",
    "href": "lessons/visium_hd.html#downloading-the-data",
    "title": "Visium HD Analysis",
    "section": "Downloading the Data",
    "text": "Downloading the Data\nFor this module, we will be working within an RStudio project. In order to follow along you should have downloaded the R project.\n\n\n\n\n\n\nWhere to download the data\n\n\n\nIf you haven’t done this already, the project is located in “Dataset for workshop” -&gt; “Day 2- NGS-based- VisiumHD” in the course DropBox.\n\n\nOnce downloaded, you should see a file called visiumHD_nanocourse.zip on your computer (likely, in your Downloads folder).\n\nUnzip this file. This will result in a folder of the same name.\nMove the folder to the location on your computer where you would like to perform the analysis.\nOpen up the folder. The contents will look like the screenshot below:\n\n\n\nLocate the .Rproj file and double-click on it. This will open up RStudio with the “visiumHD_nanocourse” project loaded.\nOpen a new Rscript file.\nStart with some comments to indicate what this file is going to contain:\n\n\n# February 2026\n# Spatial Transcriptomics\n# Visium HD Demo\n# Harvard Chan Bioinformatics Core\n\n\nSave the Rscript in the code folder as visiumHD.R. Your working directory should look something like this:"
  },
  {
    "objectID": "lessons/visium_hd.html#explore-the-object",
    "href": "lessons/visium_hd.html#explore-the-object",
    "title": "Visium HD Analysis",
    "section": "Explore the Object",
    "text": "Explore the Object\nLet’s read in the Seurat object and talk about some very basic slots that we will be accessing.\n\n# Load in Seurat object\n# object &lt;- qread('data_processed/MsBrain_FF-A1_subset.qs')\n# object &lt;- UpdateSeuratObject(object)\n\nobject &lt;- readRDS(\"data_processed/MsBrain_FF-A1_subset_updated.rds\")\n\nWe can print the Seurat object by calling the object we created in the console:\n\nobject\n\nAn object of class Seurat \n32285 features across 43167 samples within 1 assay \nActive assay: Spatial.016um (32285 features, 0 variable features)\n 1 layer present: counts\n 1 spatial field of view present: slice1.016um\n\n\nNow we can examine its major features, which we will add to and alter throughout the lesson:\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThere are 3 things about our Seurat object printout that would be different if we were using the 8µm x 8µm binning instead of the 16µm x 16µm binning. What are these three differences?\n\n\n\n\n\n\nClick here to use an app that lets you explore different bin sizes for this Seurat object"
  },
  {
    "objectID": "lessons/visium_hd.html#pre-filtering",
    "href": "lessons/visium_hd.html#pre-filtering",
    "title": "Visium HD Analysis",
    "section": "Pre-filtering",
    "text": "Pre-filtering\nTo create some plots first, we will need to create a metadata object using this command:\n\nobject_meta &lt;- object@meta.data\n\nNow we can plot the number of UMIs (nCount) and the number of genes (nFeature) side-by-side. For both of the plots, we expect to see a bimodal distribution, with one peak representing bins containing lower-quality cells with fewer genes and UMIs and another peak representing bins containing healthy cells with more genes and UMIs. Ideally, the peak representing lower-quality and dying cells is small and the peak representing healthy cells is large.\n\n# Create a plot for nUMI\ndist_counts_before &lt;- object_meta %&gt;%\n  ggplot(aes(x=nCount_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of UMIs per bin\") +\n  ggtitle('Pre-QC UMIs/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Create a plot for nGene\ndist_features_before &lt;- object_meta %&gt;%\n  ggplot(aes(x=nFeature_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of genes per bin\") +\n  ggtitle('Pre-QC Genes/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\ndists_before &lt;- dist_counts_before | dist_features_before\ndists_before\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUsing the distribution plots in the app below, what do you think would be good minimum thresholds for nGene and nUMI?"
  },
  {
    "objectID": "lessons/visium_hd.html#post-filtering",
    "href": "lessons/visium_hd.html#post-filtering",
    "title": "Visium HD Analysis",
    "section": "Post-Filtering",
    "text": "Post-Filtering\nWe will apply very minimal filtering here, with nUMI &gt; 100 and nGene &gt; 100. It has been shown that low expression can be biologically meaningful for spatial context so we won’t be as stringent as we normally are with scRNA-seq.\n\n# Create a filtered object\nobject_filt &lt;- subset(object, \n                      subset = (nCount_Spatial.016um &gt; 100) & \n                               (nFeature_Spatial.016um &gt; 100))\n\nNow, we can create similar plots with filtered data. As expected, we see that the small left peak in the distribution has vanished, leaving the higher quality bins, which are the majority of the data.\n\n# Create a new metadata data frame from filtered data\nobject_filt_meta &lt;- object_filt@meta.data\n\n# Plot nUMI\ndist_counts_after &lt;- object_filt_meta %&gt;%\n  ggplot(aes(x=nCount_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of UMIs per bin\") +\n  ggtitle('PostQC UMIs/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Plot nGene\ndist_features_after &lt;- object_filt_meta %&gt;%\n  ggplot(aes(x=nFeature_Spatial.016um)) +\n  geom_density(alpha = 0.2) +\n  scale_x_log10() +\n  theme_classic() +\n  ylab(\"Cell density\") +\n  xlab(\"Number of genes per bin\") +\n  ggtitle('PostQC Genes/Bin') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Combine plots side-by-side\ndists_after &lt;- dist_counts_after | dist_features_after\ndists_after\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow many cells did we filter out with these thresholds?"
  },
  {
    "objectID": "lessons/visium_hd.html#visualizing-counts-data",
    "href": "lessons/visium_hd.html#visualizing-counts-data",
    "title": "Visium HD Analysis",
    "section": "Visualizing Counts Data",
    "text": "Visualizing Counts Data\nWe can visualize the number of UMIs and gene counts per bin, both as a distribution and layered on top of the tissue image. Let’s start with a violin plot to look at the distribution of UMI counts and gene counts. The input is our post-filtered dataset.\n\n# Violin plot of UMI counts\nvln_counts_after &lt;- VlnPlot(object_filt, \n                            features = \"nCount_Spatial.016um\", \n                            pt.size = 0, \n                            group.by = 'orig.ident') + \n  NoLegend() + scale_y_log10() + ggtitle('nUMI') + xlab('') + ylim(c(100, 15000))\n\n# Violin plot of gene counts\nvln_features_after &lt;- VlnPlot(object_filt, \n                            features = \"nFeature_Spatial.016um\", \n                            pt.size = 0, \n                            group.by = 'orig.ident') + \n  NoLegend() + scale_y_log10() + ggtitle('nGene') +  xlab('') + ylim(c(100, 15000))\n\n\n# Plot both side by side\nvln_counts_after | vln_features_after\n\n\n\n\n\n\n\n\nWe see that both distributions have a similar peak but the nUMI distribution has a much longer tail. This is expected, because while the small physical size of the bins means that most genes will be detected only once or twice, a minority of bins under very transcriptionally active cells may exhibit multiple transcripts of the same gene.\nNext, we can look at the same metrics and the distribution on the actual image itself. Note that many spots have very few counts, in part due to low cellular density or cell types with low complexity in certain tissue regions.\n\n# Visualizing UMI count across the image\nimage_counts &lt;- SpatialFeaturePlot(object_filt, \n                                   feature = 'nCount_Spatial.016um', \n                                   pt.size.factor = 8)\n\n# Visualizing gene count across the image\nimage_features &lt;- SpatialFeaturePlot(object_filt, \n                                     features = \"nFeature_Spatial.016um\", \n                                     pt.size.factor = 8) \n\n# Plot the two side-by-side\nimage_counts | image_features"
  },
  {
    "objectID": "lessons/visium_hd.html#sketch-downsampling",
    "href": "lessons/visium_hd.html#sketch-downsampling",
    "title": "Visium HD Analysis",
    "section": "Sketch Downsampling",
    "text": "Sketch Downsampling\nNext, we select 10,000 cells and create a new sub-sampled “sketch” assay using the SketchData() function. The function takes a normalized single-cell dataset containing a set of variable features and returns a Seurat object with a new assay (sketch), consisting of 10,000 bins selected based off a “leverage score” for each bin.\nThe leverage score reflects the magnitude of its contribution to the gene-covariance matrix, and its importance to the overall dataset, with rare populations earning a higher leverage score. This means that our 10,000 cells selected for the sketch will oversample rare populations, retaining the biological complexity of the sample, while drastically compressing the dataset.\n\n# we select 10,000 cells and create a new 'sketch' assay\nobject_filt &lt;- SketchData(\n  object = object_filt,\n  assay = 'Spatial.016um',\n  ncells = 10000,\n  method = \"LeverageScore\",\n  sketched.assay = \"sketch\"\n)\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 2 layers present: counts, data\n 1 other assay present: Spatial.016um\n 1 spatial field of view present: slice1.016um\n\n\nWe see that there are four major changes that have taken place in our Seurat object:\n\nThe number of features in the second line has double, because we have added a new assay\nAccordingly, the number of assays has increased from one to two\nThe active assay has change from Spatial.016um to sketch\nThere is a new line listing additional assays that exist in the Seurat object\n\n\n\n\nWe can also see that the leverage score has been added as a column to the metadata of our object.\n\nView(object_filt@meta.data)"
  },
  {
    "objectID": "lessons/visium_hd.html#clustering-workflow",
    "href": "lessons/visium_hd.html#clustering-workflow",
    "title": "Visium HD Analysis",
    "section": "Clustering Workflow",
    "text": "Clustering Workflow\nNext, we will perform a standard clustering workflow on our sketch of 10,000 cells:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nFindVariableFeatures()\nAs before, this generates a list of highly variable genes.\n\n\nScaleData()\nHighly variable genes will be confounded with the most highly expressed genes, so we need to adjust for this.\n\n\nRunPCA()\nPerform a principal component analysis using our scaled data and variable genes. This will emphasize variation in gene expression as well as similarity across bins.\n\n\nFindNeighbors()\nDetermine the Euclidean distance between bins in PCA space.\n\n\nFindClusters()\nIteratively group bins together based on neighborhood distances. Higher resolution will yield more groups.\n\n\n\n\n\n\n\n\n\nscRNA-seq workflow\n\n\n\n\n\nThese steps are all a part the standard single-cell RNA-seq workflow. For more detailed information on what each of these steps are, we have a scRNA workshop that detailed each of these steps shown in the following workflow and considerations that should be made:\n\n\n\n\n\n\n\nVariable Features\nWe calculate the HVGs to use as input for the next step, which is PCA. We can also visualize each gene’s average expression across the bins on the x-axis and variance on the y-axis.\n\nobject_filt &lt;- FindVariableFeatures(object_filt)\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(object_filt,\n                                          assay = \"sketch\")\ntop_genes &lt;- ranked_variable_genes[1:15]\n\n# Plot the average expression and variance of these genes\n# With labels to indicate which genes are in the top 15\np &lt;- VariableFeaturePlot(object_filt)\nLabelPoints(plot = p, points = top_genes, repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nYou may notice that the top variable features are slightly different from when we calculated them previously. Why might that be the case?\n\n\n\n\nPCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for dimensionality reduction. Ultimately what we have calculated with PCA are values that can represent how similar bins are to one another.\nWe would expect that bins with similar gene expression will have similar PC values. For example, we would anticipate that two Fibroblast cells would have comparable gene expression - which would also results in similar scores in principal components. This is why many of the downstream steps in the remainder of this lesson use PCA as the input.\n\nobject_filt &lt;- ScaleData(object_filt)\nobject_filt &lt;- RunPCA(object_filt, assay = \"sketch\", \n                      reduction.name = \"pca.sketch\")\n\nOne way of exploring the PCs is using a heatmap to visualize the most variant genes for select PCs with the genes and bins ordered by PC scores. The idea here is to look at the PCs and determine whether the genes driving them make sense for differentiating the different cell types. Where we would expect to see a large differences in the genes that have positive versus negative scores.\n\n# TODO: is this a helpful visualization??\n# Explore heatmap of PCs \nDimHeatmap(object_filt, \n           reduction = \"pca.sketch\",\n           dims = 1:6, \n           cells = 500, \n           balanced = TRUE)\n\n\n\n\n\n\n\n\n\n\nNeighborhoods and Clusters\nTo group our bins together, the first step is to construct a K-nearest neighbor (KNN) graph based on the PCA space. Where edges are drawn between bins with similar features expression patterns. Then, edge weights are refined between any two bins based on shared overlap in their local neighborhoods.\nFrom these neighborhoods, the FindClusters() function will iteratively group bins together using the Louvain algorithm. The size of clusters is determined by the resolution parameter. Larger resolution values lead to a more clusters, which is often required for big datasets. Typically you would test a variety of different cluster resolutions to see which best represents the different cell states in your dataset.\nHere we are going to use resolution = 0.65.\n\n# K-nearest neighbors\nobject_filt &lt;- FindNeighbors(object_filt, assay = \"sketch\", \n                             reduction = \"pca.sketch\", dims = 1:50)\n\n# Louvain clustering\nobject_filt &lt;- FindClusters(object_filt, \n                            cluster.name = \"seurat_cluster.sketched\", \n                            resolution = 0.65)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10000\nNumber of edges: 401729\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9013\nNumber of communities: 20\nElapsed time: 0 seconds\n\n\nWe can also see how many bins belong to each one of our clusters:\n\nggplot(object_filt@meta.data) +\n  geom_bar(aes(x = seurat_cluster.sketched, \n               fill = seurat_cluster.sketched)) +\n  theme_bw() + NoLegend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhy are there so many NA values in our results?\n\n\n\n\nUMAP\nFinally, let’s create a UMAP using the principal components as input. UMAP is a method that aims to place cells with similar local neighborhoods in high-dimensional space together in low-dimensional space, which is useful for visualizing our newly calculated clusters. We observe good separation between groups annotated as separate clusters, which is sign that our clustering indeed represents various cell types.\n\nobject_filt &lt;- RunUMAP(object_filt, reduction = \"pca.sketch\", \n                       reduction.name = \"umap.sketch\", return.model = T, \n                       dims = 1:50)\n\n# Plot UMAP\nDimPlot(object_filt, reduction = \"umap.sketch\", \n        label = T, cols = 'polychrome') + \n  ggtitle(\"Sketched clustering\") + NoLegend()\n\n\n\n\n\n\n\n\nWe can also examine our object after these manipulations and note the addition of the scale.data layer as well as the sketch PCA and UMAP dimensional reductions.\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.016um\n 2 dimensional reductions calculated: pca.sketch, umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nShould return:"
  },
  {
    "objectID": "lessons/visium_hd.html#umap",
    "href": "lessons/visium_hd.html#umap",
    "title": "Visium HD Analysis",
    "section": "UMAP",
    "text": "UMAP\nFinally, let’s create a UMAP using the principal components as input. UMAP is a method that aims to place cells with similar local neighborhoods in high-dimensional space together in low-dimensional space, which is useful for visualizing our newly calculated clusters. We observe good separation between groups annotated as separate clusters, which is sign that our clustering indeed represents various cell types.\n\nobject_filt &lt;- RunUMAP(object_filt, reduction = \"pca.sketch\", \n                       reduction.name = \"umap.sketch\", return.model = T, \n                       dims = 1:50)\n\n# Plot UMAP\nDimPlot(object_filt, reduction = \"umap.sketch\", label = T, \n        cols = 'polychrome') + \n  ggtitle(\"Sketched clustering\") + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe can also examine our object after these manipulations and note the addition of the scale.data layer as well as the sketch PCA and UMAP dimensional reductions.\n\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.016um\n 2 dimensional reductions calculated: pca.sketch, umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nShould return:"
  },
  {
    "objectID": "lessons/visium_hd.html#project-clusters-back-to-entire-dataset",
    "href": "lessons/visium_hd.html#project-clusters-back-to-entire-dataset",
    "title": "Visium HD Analysis",
    "section": "Project Clusters Back to Entire Dataset",
    "text": "Project Clusters Back to Entire Dataset\nNow that we have our clusters and dimensional reductions from our sketched dataset, we need to extend these to the full dataset. The ProjectData function projects all the bins in the dataset (the Spatial.016um assay) onto the sketch assay.\n\nobject_filt &lt;- ProjectData(\n  object = object_filt,\n  assay = \"Spatial.016um\",\n  full.reduction = \"full.pca.sketch\",\n  sketched.assay = \"sketch\",\n  sketched.reduction = \"pca.sketch\",\n  umap.model = \"umap.sketch\",\n  dims = 1:50,\n  refdata = list(seurat_cluster.projected = \"seurat_cluster.sketched\")\n)\nobject_filt\n\nAn object of class Seurat \n64570 features across 41818 samples within 2 assays \nActive assay: sketch (32285 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 other assay present: Spatial.016um\n 4 dimensional reductions calculated: pca.sketch, umap.sketch, full.pca.sketch, full.umap.sketch\n 1 spatial field of view present: slice1.016um\n\n\nUsing the sketch PCA and UMAP, the ProjectData function returns a Seurat object that includes:\n\nDimensional reduction (PCA) - The full.pca.sketch dimensional reduction extends the PCA reduction on the sketched cells to all bins in the dataset\nDimensional reduction (UMAP) - The full.umap.sketch dimensional reduction extends the UMAP reduction on the sketched cells to all bins in the dataset\nCluster labels - The seurat_cluster.projected column in the object metadata now labels all cells in the dataset with one of the cluster labels derived from the sketched cells\n\nWe can now see the additional full-dataset reductions in the object.\n\n\n\nNote that a score for the projection of each bin will be saved as a column in the metadata. Actually opening up the metadata again gives the opportunity to look at the seurat_cluster.sketched column and see many NA values, because it was only calculated for 10,000 bins. The seurat_cluster.projected shows values for every bin.\n\nView(object_filt@meta.data)\n\n\n\n\n\n\n\n\nVisualizing the Projected Clusters on UMAP\nWe can now visualize our clusters from the projected assignments. The UMAP plot now contains more points, which is expected because we are now visualizing the full dataset rather than our 10,000 bin sketch. Nonetheless, we can see that the full dataset is still well-represented by the projected dimensional reduction and clustering.\n\n# switch to full dataset assay\nDefaultAssay(object_filt) &lt;- \"Spatial.016um\"\n\n# Change the idents to the projected cluster assignments\nIdents(object_filt) &lt;- \"seurat_cluster.projected\"\n\n# Plot the UMAP\nDimPlot(object_filt, reduction = \"full.umap.sketch\", label = T, \n        raster = F, cols = 'polychrome') +\n  ggtitle(\"Projected clustering\") + NoLegend()\n\n\n\n\n\n\n\n\n\n\nVisualizing Projected Clusters on the Image\nIn order to see the clusters superimposed on our image we can use the SpatialDimPlot() function. We will also set the color palette and convert the cluster assignments to a factor so they are ordered numerically rather than lexicographically in the figure.\n\n# Sort clusters so they get listed in numerical order\norder &lt;- object_filt$seurat_cluster.projected %&gt;%\n  unique() %&gt;% as.numeric() %&gt;%\n  sort() %&gt;% as.character()\n\nobject_filt$seurat_cluster.projected &lt;- factor(object_filt$seurat_cluster.projected,\n                                               levels = order)\n\n# Create color palette\ncolor_pal &lt;- Seurat::DiscretePalette(n = length(order),\n                                     palette = \"polychrome\")\nnames(color_pal) &lt;- order\n\n# Visualize clusters on slide\nimage_seurat_clusters &lt;- SpatialDimPlot(object_filt, \n                                        group.by = 'seurat_cluster.projected', \n                                        pt.size.factor = 8, cols = color_pal) +\n  guides(fill=guide_legend(ncol=2))\n\nimage_seurat_clusters"
  },
  {
    "objectID": "lessons/visium_hd.html#variable-features",
    "href": "lessons/visium_hd.html#variable-features",
    "title": "Visium HD Analysis",
    "section": "Variable Features",
    "text": "Variable Features\nWe calculate the HVGs to use as input for the next step, which is PCA. We can also visualize each gene’s average expression across the bins on the x-axis and variance on the y-axis.\n\nobject_filt &lt;- FindVariableFeatures(object_filt)\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(object_filt,\n                                          assay = \"sketch\")\ntop_genes &lt;- ranked_variable_genes[1:15]\n\n# Plot the average expression and variance of these genes\n# With labels to indicate which genes are in the top 15\np &lt;- VariableFeaturePlot(object_filt)\nLabelPoints(plot = p, points = top_genes, repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nYou may notice that the top variable features are slightly different from when we calculated them previously. Why might that be the case?"
  },
  {
    "objectID": "lessons/visium_hd.html#pca",
    "href": "lessons/visium_hd.html#pca",
    "title": "Visium HD Analysis",
    "section": "PCA",
    "text": "PCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for dimensionality reduction. Ultimately what we have calculated with PCA are values that can represent how similar bins are to one another.\nWe would expect that bins with similar gene expression will have similar PC values. For example, we would anticipate that two Fibroblast cells would have comparable gene expression - which would also results in similar scores in principal components. This is why many of the downstream steps in the remainder of this lesson use PCA as the input.\n\nobject_filt &lt;- ScaleData(object_filt)\nobject_filt &lt;- RunPCA(object_filt, assay = \"sketch\", \n                      reduction.name = \"pca.sketch\")\n\nOne way of exploring the PCs is using a heatmap to visualize the most variant genes for select PCs with the genes and bins ordered by PC scores. The idea here is to look at the PCs and determine whether the genes driving them make sense for differentiating the different cell types. Where we would expect to see a large differences in the genes that have positive versus negative scores.\n\n# Explore heatmap of PCs \nDimHeatmap(object_filt, \n           reduction = \"pca.sketch\",\n           dims = 1:6, \n           cells = 500, \n           balanced = TRUE)"
  },
  {
    "objectID": "lessons/visium_hd.html#neighborhoods-and-clusters",
    "href": "lessons/visium_hd.html#neighborhoods-and-clusters",
    "title": "Visium HD Analysis",
    "section": "Neighborhoods and Clusters",
    "text": "Neighborhoods and Clusters\nTo group our bins together, the first step is to construct a K-nearest neighbor (KNN) graph based on the PCA space. Where edges are drawn between bins with similar features expression patterns. Then, edge weights are refined between any two bins based on shared overlap in their local neighborhoods.\nFrom these neighborhoods, the FindClusters() function will iteratively group bins together using the Louvain algorithm. Where the size of clusters are determined by the resolution parameter. Larger resolution values lead to a more clusters, which is often required for big datasets. Typically you would test a variety of different cluster resolutions to see which best represents the different cell states in your dataset.\nHere we are going to use resoultion = 0.65.\n\nobject_filt &lt;- FindNeighbors(object_filt, assay = \"sketch\", \n                             reduction = \"pca.sketch\", dims = 1:50)\nobject_filt &lt;- FindClusters(object_filt, \n                            cluster.name = \"seurat_cluster.sketched\", \n                            resolution = 0.65)\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 10000\nNumber of edges: 401729\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9013\nNumber of communities: 20\nElapsed time: 0 seconds\n\n\nWe can also see how many bins belong to each one of our clusters:\n\nggplot(object_filt@meta.data) +\n  geom_bar(aes(x = seurat_cluster.sketched, \n               fill = seurat_cluster.sketched)) +\n  theme_bw() + NoLegend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhy are there so many NA values in our results?"
  },
  {
    "objectID": "lessons/visium_hd.html#sketch-and-process-the-spatial-query-dataset",
    "href": "lessons/visium_hd.html#sketch-and-process-the-spatial-query-dataset",
    "title": "Visium HD Analysis",
    "section": "1) Sketch and process the spatial query dataset",
    "text": "1) Sketch and process the spatial query dataset\nAs we have subset the dataset, we need to re-run the typical scRNA workflow. This is due to the fact that we would be able to recognize more subtle shifts in these cortex bins as we do not have the rest of the dataset weights to consider anymore.\n\n# Create sketch of cortex subset\nDefaultAssay(cortex) &lt;- 'Spatial.016um'\ncortex &lt;- FindVariableFeatures(cortex)\ncortex &lt;- SketchData(\n  object = cortex,\n  ncells = 3000,\n  method = \"LeverageScore\",\n  sketched.assay = \"sketch\"\n)\n\n# Run through scRNA workflow\nDefaultAssay(cortex) &lt;- \"sketch\"\ncortex &lt;- ScaleData(cortex)\ncortex &lt;- RunPCA(cortex, assay = \"sketch\", \n                 reduction.name = \"pca.cortex.sketch\", verbose = T)\ncortex &lt;- FindNeighbors(cortex, reduction = \"pca.cortex.sketch\", dims = 1:50)\ncortex &lt;- RunUMAP(cortex, reduction = \"pca.cortex.sketch\", \n                  reduction.name = \"umap.cortex.sketch\", return.model = T, \n                  dims = 1:50, verbose = T)\n\nRCTD requires a unique data structure (similar to Seurat) as input to run. So we create our query object with SpatialRNA() by suppling the spatial coordinates and raw counts for our cells.\n\n# Create the RCTD query object\n# Only using sketched cells\ncounts_hd &lt;- cortex[[\"sketch\"]]$counts\ncortex_cells_hd &lt;- colnames(cortex[[\"sketch\"]])\ncoords &lt;- GetTissueCoordinates(cortex)[cortex_cells_hd, 1:2]\nquery &lt;- SpatialRNA(coords, counts_hd, colSums(counts_hd))"
  },
  {
    "objectID": "lessons/visium_hd.html#mouse-brain-visium-hd-dataset",
    "href": "lessons/visium_hd.html#mouse-brain-visium-hd-dataset",
    "title": "Visium HD Analysis",
    "section": "Mouse Brain Visium HD Dataset",
    "text": "Mouse Brain Visium HD Dataset\nThe Visium HD platform is compatible with human and mouse fresh frozen, fixed frozen, and formalin-fixed paraffin-embedded (FFPE) tissue sections. For this lesson, we will be working with data from a fresh frozen coronal section of a mouse brain sample.\nEach Visium HD slide has the same 6.5 x 6.5mm capture area as previous Visium products but is covered with about 11 million tiles. These 2µm x 2µm squares are arrayed in a continuous lawn across the entire capture area. The squares are each uniquely barcoded with an oligonucleotide and contain probes allowing for the detection of the full coding transcriptome. As such, Visium HD is categorized as a sequencing-based technology.\n\n\n\nThe single-digit micron resolution is a big technological improvement over original Visium’s original ∼55μm spots. Due to the size of the bin, multiple cells would exist in each spot. As a result, this dataset can be challenging to annotate, where many methods would attempt to quantify the “proportion” of a spot is assigned to various celltypes.\n\n\n\nMa, Y., et al. Nat Biotechnol (2022), Figure 1\n\n\nWhile Visium HD has reduced the size of bins to achieve near single-cell level, it is important to bear in mind that these sequencing-based technologies can capture more than one cell in a spot. This information is important to bear in mind in downstream steps, such as differential gene expression.\n\n\n\n\n\n\nImaging-based technologies\n\n\n\n\n\nThese methods utilize floresence to quantify gene expression on a tissue slide. Specifically utilizing fluoresence in situ hybridization (FISH) to measure expression of a select panel of genes (selected by the researcher) using probes. Therefore we are able to evaluate the expression for each individual cell after segmentation.\nSome popular imaging-based technologies include:\n\nseqFISH\nMERFISH\nXenium"
  },
  {
    "objectID": "lessons/visium_hd.html#ngs-based-spatial-transcriptomics-analysis-workflow",
    "href": "lessons/visium_hd.html#ngs-based-spatial-transcriptomics-analysis-workflow",
    "title": "Visium HD Analysis",
    "section": "NGS-based Spatial Transcriptomics Analysis Workflow",
    "text": "NGS-based Spatial Transcriptomics Analysis Workflow\nThe overarching steps for analyzing a sequencing-based transcriptomics dataset is as follows:"
  },
  {
    "objectID": "lessons/visium_hd.html#highly-variable-genes-hvgs",
    "href": "lessons/visium_hd.html#highly-variable-genes-hvgs",
    "title": "Visium HD Analysis",
    "section": "Highly Variable Genes (HVGs)",
    "text": "Highly Variable Genes (HVGs)\nWe will start by defining a set of highly variable genes. Note that this is being done on all bins in our object. Using this list of genes will help us to quantify the variability and similarity between bins. Essentially, we are looking at genes with high levels of variance while also accounting for the average expression. In doing so, we get a list of genes ranked by how much they change across different cell populations.\n\nobject_filt &lt;- FindVariableFeatures(object_filt)\nobject_filt\n\nAn object of class Seurat \n32285 features across 41818 samples within 1 assay \nActive assay: Spatial.016um (32285 features, 2000 variable features)\n 2 layers present: counts, data\n 1 spatial field of view present: slice1.016um\n\n\nWhen we examine our Seurat object, we can see that FindVariableFeatures() has added 2,000 variable features.\n\n\n\nAnd we can even take a look at what the top 15 most variables features are for the entire dataset. We would anticipate that these genes correspond to the celltypes in our dataset.\n\nVariableFeatures(object_filt)[1:15]\n\n [1] \"Ttr\"    \"Enpp2\"  \"Sst\"    \"Igf2\"   \"Ecrg4\"  \"Ptgds\"  \"Npy\"    \"Prlr\"  \n [9] \"Clic6\"  \"Hbb-bs\" \"Kl\"     \"Igfbp2\" \"Tac2\"   \"Hba-a2\" \"Cnr1\"  \n\n\nIf we read more about the gene Ttr, we can learn that it is “highly expressed in choroid plexus epithelial cells”. If we were to continue looking at the top variable genes, we would hope to see more genes with experimental or celltype specific relevance."
  },
  {
    "objectID": "lessons/visium_hd.html#load-and-format-the-reference-dataset",
    "href": "lessons/visium_hd.html#load-and-format-the-reference-dataset",
    "title": "Visium HD Analysis",
    "section": "2) Load and format the reference dataset",
    "text": "2) Load and format the reference dataset\nAfter loading our reference dataset, we can take a quick look at the different celltypes that we are going to try annotating our query object with. These values are stored in the column subclass_label.\n\n# Increase amoutn of memory R can use\nmem.maxVSize(15000)\n\n[1] 15000\n\nref_subset &lt;- qread(\"data_processed/allen_scRNAseq_ref_subset.qs\")\n\nggplot(ref_subset@meta.data) +\n  geom_bar(aes(x = subclass_label, \n               fill = subclass_label)) +\n  theme_bw() + NoLegend() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\n\n\n\n\nWe are going to make another RCTD object out of the reference dataset. This time we use the Reference() function and additionally supply cluster (celltype) information to transfer to our query.\n\nIdents(ref_subset) &lt;- \"subclass_label\"\ncounts &lt;- ref_subset[[\"RNA\"]]$counts\ncluster &lt;- as.factor(ref_subset$subclass_label)\nnUMI &lt;- ref_subset$nCount_RNA\nlevels(cluster) &lt;- gsub(\"/\", \"-\", levels(cluster))\ncluster &lt;- droplevels(cluster)\n\n# create the RCTD reference object\nreference &lt;- Reference(counts, cluster, nUMI)"
  },
  {
    "objectID": "lessons/visium_hd.html#apply-rctd-to-deconvolute-the-sketched-cortical-cells-and-annotate-them",
    "href": "lessons/visium_hd.html#apply-rctd-to-deconvolute-the-sketched-cortical-cells-and-annotate-them",
    "title": "Visium HD Analysis",
    "section": "3) Apply RCTD to deconvolute the “sketched” cortical cells and annotate them",
    "text": "3) Apply RCTD to deconvolute the “sketched” cortical cells and annotate them\nNote that run.RCTD takes 10-15 minutes to complete on a laptop using 6 cores\n\n# run RCTD\nRCTD &lt;- create.RCTD(query, reference, max_cores = 6)\nRCTD &lt;- run.RCTD(RCTD, doublet_mode = \"doublet\") # this command takes ~15 mins to run\n\n# add results back to Seurat object\ncortex &lt;- AddMetaData(cortex, metadata = RCTD@results$results_df)\n\n\n\n\n\n\n\nRCTD output\n\n\n\n\n\nThe resultant dataframe from RCTD will contain the following columns according to the documentation:\n\nspot_class, a factor variable representing RCTD’s classification in doublet mode:\n\n“singlet” (1 cell type on pixel)\n“doublet_certain” (2 cell types on pixel)\n“doublet_uncertain” (2 cell types on pixel, but only confident of 1)\n“reject” (no prediction given for pixel)\n\nfirst_type column gives the first cell type predicted on the bead (for all spot_class conditions except “reject”).\nsecond_type column gives the second cell type predicted on the bead for doublet spot_class conditions (not a confident prediction for “doublet_uncertain”).\n\nWhich we can access from our cortex object:\n\ncols &lt;- c(\"spot_class\", \"first_type\", \"second_type\")\ncortex@meta.data[cols] %&gt;%\n  subset(!is.na(spot_class)) %&gt;%\n  View()"
  },
  {
    "objectID": "lessons/visium_hd.html#project-rctd-labels-onto-all-cortical-cells",
    "href": "lessons/visium_hd.html#project-rctd-labels-onto-all-cortical-cells",
    "title": "Visium HD Analysis",
    "section": "4) Project RCTD labels onto all cortical cells",
    "text": "4) Project RCTD labels onto all cortical cells\nWe once again use the ProjectData() function in order to annotate the full dataset, not just the sketch. These values will be stored in a new column named full_first_type\n\n# Set all NA values to \"Unkown\"\ncortex$first_type &lt;- as.character(cortex$first_type)\ncortex$first_type[is.na(cortex$first_type)] &lt;- \"Unknown\"\n\n# Project back first_type to new column called full_first_type\ncortex &lt;- ProjectData(\n  object = cortex,\n  assay = \"Spatial.016um\",\n  full.reduction = \"pca.cortex\",\n  sketched.assay = \"sketch\",\n  sketched.reduction = \"pca.cortex.sketch\",\n  umap.model = \"umap.cortex.sketch\",\n  dims = 1:50,\n  refdata = list(full_first_type = \"first_type\")\n)\n\nTo visualize the cortical layers, we first identify all the cells that belong to each annotation with CellsByIdentities(). Then, we select the layered neurons of interest using regular expressions. This is so that when we visualize these cells later on, we can highlight the cells on the slide in yellow to emphasize where the bins are spatially located.\n\nIdents(cortex) &lt;- \"full_first_type\"\ncells &lt;- CellsByIdentities(cortex)\n\n# Layered (starts with L), excitatory neurons in the cortex\nexcitatory_names &lt;- sort(grep(\"^L.* CTX\", names(cells), value = TRUE))\nexcitatory_names\n\n[1] \"L2-3 IT CTX\" \"L4-5 IT CTX\" \"L5 IT CTX\"   \"L5 PT CTX\"   \"L5-6 NP CTX\"\n[6] \"L6 CT CTX\"   \"L6 IT CTX\"   \"L6b CTX\"    \n\n\nWe can see that the excitatory neurons are located in layers at varying cortical depths, as expected.\n\nSpatialDimPlot(cortex, cells.highlight = cells[excitatory_names], \n               cols.highlight = c(\"#FFFF00\", \"grey50\"), facet.highlight = T, \n               combine = T, ncol = 4, pt.size.factor = 8)"
  }
]